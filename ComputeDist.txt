import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
//import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
//import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;


public class LCS {
public static int max(int a, int b) {
if(a>=b)
return a;
else
return b;
}
    public static class Map extends
            Mapper<Object, Text, IntWritable, Text> {
    private Text txt = new Text();
    private int c=1;
    private int g=2;
        @Override
        public void map(Object key, Text value, Context context)
                throws IOException, InterruptedException {
       
        int len=0;
        IntWritable i=new IntWritable();
        StringTokenizer itr = new StringTokenizer(value.toString(),"\n",false);
        String comp="", seq1="", seq2="";
        int nb_comp=itr.countTokens();
        int nb_seq=(int) ((1+Math.sqrt(1+8*nb_comp))/2);
        while (itr.hasMoreTokens()) {
            comp=itr.nextToken();
            seq1=comp.substring(0, comp.indexOf(';'));
            seq2=comp.substring(comp.indexOf(';')+1,comp.indexOf('N'));
           
            if(seq1!=null && seq2!=null) {
                int[][] l = new int[seq1.length()+1][seq2.length()+1];
            for(int k=1;k<seq1.length()+1;k++)
    l[k][0]=0;
    for(int k=1;k<seq2.length()+1;k++)
    l[0][k]=0;
    for(int k=1;k<seq1.length()+1;k++) {
    for(int p=1;p<seq2.length()+1;p++)
    if(seq1.charAt(k-1)==seq2.charAt(p-1))
    l[k][p]=l[k-1][p-1]+1;
    else
    l[k][p]=max(l[k-1][p],l[k][p-1]);}
    len = l[seq1.length()][seq2.length()];}
           
            int f;
           
            if(seq1.length()==seq2.length())
            f=1;
            else
            f=2*Math.abs(seq1.length()-seq2.length());
           
            //i.set(1/(f*(seq1.length()+seq2.length())/(2*len)));
            i.set(f*(seq1.length()+seq2.length())-2*len);
            txt.set("("+c+","+g+")");
           
            if(g>nb_seq) {
            c++;
            g=c+1;}
            else
            g++;
           
            context.write(i, txt);
        }
    }
        }

    public static class Reduce extends
            Reducer<IntWritable, Text, Text, IntWritable> {

        @Override
        public void reduce(IntWritable key, Iterable<Text> values,
                Context context) throws IOException, InterruptedException {
       
            for (Text t : values)
            context.write(t, key);
        }
    }
   
    public static void main(String[] args) throws Exception {
   
        Configuration conf = new Configuration();
        Job job = new Job(conf);
        job.setJarByClass(LCS.class);
        job.setJobName("LCS");

        job.setMapOutputKeyClass(IntWritable.class);
        job.setMapOutputValueClass(Text.class);

        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        job.setMapperClass(Map.class);
        job.setReducerClass(Reduce.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        //MultipleInputs.addInputPath(job, new Path(args[1]), TextInputFormat.class, Map2.class);
        //job.waitForCompletion(true);
        System.exit(job.waitForCompletion(true) ? 0 : 1);

    }

}